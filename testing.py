{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first import the excel sheet\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from plotly import graph_objects as go\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "import numpy as np\n",
    "import spacy\n",
    "from collections import Counter\n",
    "\n",
    "import dash\n",
    "from dash import dcc, html, dash_table\n",
    "from dash.dependencies import Input, Output\n",
    "\n",
    "import dash_bootstrap_components as dbc #used for formatting layout of the dash\n",
    "\n",
    "file_path = \"C:/Users/rgae/OneDrive - QuidelOrtho/Documents/All QuidelFiles/Excel Files/6-27-2024 2nd Copy .xlsx\"\n",
    "df = pd.read_excel(file_path, usecols = 'AP, AV, AZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_AZ = df.loc[df['Action Taken Description'] == 'CLOSE A CALL'].copy()\n",
    "\n",
    "#Verify the length of the DataFrame\n",
    "length_of_df = len(df_filtered_AZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Incident Close Loc Dt</th>\n",
       "      <th>Problem Dsc</th>\n",
       "      <th>Action Taken Description</th>\n",
       "      <th>combined_text</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-06-01 01:12:00</td>\n",
       "      <td>CUST  12:22PM SGT JUNE 1,2023    PROBLEM STATE...</td>\n",
       "      <td>CLOSE A CALL</td>\n",
       "      <td>2023-06-01 01:12:00 CUST  12:22PM SGT JUNE 1,2...</td>\n",
       "      <td>cust   12:22pm sgt june 1,2023     problem sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-06-01 04:32:00</td>\n",
       "      <td>PROBLEM STATEMENT AND DESCRIPTION: CUST CALLED...</td>\n",
       "      <td>CLOSE A CALL</td>\n",
       "      <td>2023-06-01 04:32:00 PROBLEM STATEMENT AND DESC...</td>\n",
       "      <td>problem statement and description : cust calle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-06-01 06:37:00</td>\n",
       "      <td>PROBLEM STATEMENT AND DESCRIPTION: UDA REAGENT...</td>\n",
       "      <td>CLOSE A CALL</td>\n",
       "      <td>2023-06-01 06:37:00 PROBLEM STATEMENT AND DESC...</td>\n",
       "      <td>problem statement and description : uda reagen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023-06-01 06:37:00</td>\n",
       "      <td>PROBLEM STATEMENT AND DESCRIPTION: UDA REAGENT...</td>\n",
       "      <td>CLOSE A CALL</td>\n",
       "      <td>2023-06-01 06:37:00 PROBLEM STATEMENT AND DESC...</td>\n",
       "      <td>problem statement and description : uda reagen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2023-06-01 11:41:00</td>\n",
       "      <td>TSS QUINN DOCUMENTING UNDER SUPERVISION OF TSS...</td>\n",
       "      <td>CLOSE A CALL</td>\n",
       "      <td>2023-06-01 11:41:00 TSS QUINN DOCUMENTING UNDE...</td>\n",
       "      <td>tss quinn documenting under supervision of tss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4370</th>\n",
       "      <td>2024-06-25 10:47:00</td>\n",
       "      <td>PROBLEM STATEMENT AND DESCRIPTION: CUSTOMER CA...</td>\n",
       "      <td>CLOSE A CALL</td>\n",
       "      <td>2024-06-25 10:47:00 PROBLEM STATEMENT AND DESC...</td>\n",
       "      <td>problem statement and description : customer c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4374</th>\n",
       "      <td>2024-06-24 22:58:00</td>\n",
       "      <td>PROBLEM STATEMENT AND DESCRIPTION: CUST CALLED...</td>\n",
       "      <td>CLOSE A CALL</td>\n",
       "      <td>2024-06-24 22:58:00 PROBLEM STATEMENT AND DESC...</td>\n",
       "      <td>problem statement and description : cust calle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4378</th>\n",
       "      <td>2024-06-25 01:50:00</td>\n",
       "      <td>PROBLEM STATEMENT AND DESCRIPTION: CUST CALLED...</td>\n",
       "      <td>CLOSE A CALL</td>\n",
       "      <td>2024-06-25 01:50:00 PROBLEM STATEMENT AND DESC...</td>\n",
       "      <td>problem statement and description : cust calle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4386</th>\n",
       "      <td>2024-06-25 11:38:00</td>\n",
       "      <td>PROBLEM STATEMENT AND DESCRIPTION: CUSTOMER IS...</td>\n",
       "      <td>CLOSE A CALL</td>\n",
       "      <td>2024-06-25 11:38:00 PROBLEM STATEMENT AND DESC...</td>\n",
       "      <td>problem statement and description : customer i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4390</th>\n",
       "      <td>2024-06-26 12:27:00</td>\n",
       "      <td>PROBLEM STATEMENT AND DESCRIPTION:  CUSTOMER S...</td>\n",
       "      <td>CLOSE A CALL</td>\n",
       "      <td>2024-06-26 12:27:00 PROBLEM STATEMENT AND DESC...</td>\n",
       "      <td>problem statement and description :   customer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>906 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Incident Close Loc Dt                                        Problem Dsc  \\\n",
       "0      2023-06-01 01:12:00  CUST  12:22PM SGT JUNE 1,2023    PROBLEM STATE...   \n",
       "7      2023-06-01 04:32:00  PROBLEM STATEMENT AND DESCRIPTION: CUST CALLED...   \n",
       "11     2023-06-01 06:37:00  PROBLEM STATEMENT AND DESCRIPTION: UDA REAGENT...   \n",
       "17     2023-06-01 06:37:00  PROBLEM STATEMENT AND DESCRIPTION: UDA REAGENT...   \n",
       "24     2023-06-01 11:41:00  TSS QUINN DOCUMENTING UNDER SUPERVISION OF TSS...   \n",
       "...                    ...                                                ...   \n",
       "4370   2024-06-25 10:47:00  PROBLEM STATEMENT AND DESCRIPTION: CUSTOMER CA...   \n",
       "4374   2024-06-24 22:58:00  PROBLEM STATEMENT AND DESCRIPTION: CUST CALLED...   \n",
       "4378   2024-06-25 01:50:00  PROBLEM STATEMENT AND DESCRIPTION: CUST CALLED...   \n",
       "4386   2024-06-25 11:38:00  PROBLEM STATEMENT AND DESCRIPTION: CUSTOMER IS...   \n",
       "4390   2024-06-26 12:27:00  PROBLEM STATEMENT AND DESCRIPTION:  CUSTOMER S...   \n",
       "\n",
       "     Action Taken Description  \\\n",
       "0                CLOSE A CALL   \n",
       "7                CLOSE A CALL   \n",
       "11               CLOSE A CALL   \n",
       "17               CLOSE A CALL   \n",
       "24               CLOSE A CALL   \n",
       "...                       ...   \n",
       "4370             CLOSE A CALL   \n",
       "4374             CLOSE A CALL   \n",
       "4378             CLOSE A CALL   \n",
       "4386             CLOSE A CALL   \n",
       "4390             CLOSE A CALL   \n",
       "\n",
       "                                          combined_text  \\\n",
       "0     2023-06-01 01:12:00 CUST  12:22PM SGT JUNE 1,2...   \n",
       "7     2023-06-01 04:32:00 PROBLEM STATEMENT AND DESC...   \n",
       "11    2023-06-01 06:37:00 PROBLEM STATEMENT AND DESC...   \n",
       "17    2023-06-01 06:37:00 PROBLEM STATEMENT AND DESC...   \n",
       "24    2023-06-01 11:41:00 TSS QUINN DOCUMENTING UNDE...   \n",
       "...                                                 ...   \n",
       "4370  2024-06-25 10:47:00 PROBLEM STATEMENT AND DESC...   \n",
       "4374  2024-06-24 22:58:00 PROBLEM STATEMENT AND DESC...   \n",
       "4378  2024-06-25 01:50:00 PROBLEM STATEMENT AND DESC...   \n",
       "4386  2024-06-25 11:38:00 PROBLEM STATEMENT AND DESC...   \n",
       "4390  2024-06-26 12:27:00 PROBLEM STATEMENT AND DESC...   \n",
       "\n",
       "                                         tokenized_text  \n",
       "0     cust   12:22pm sgt june 1,2023     problem sta...  \n",
       "7     problem statement and description : cust calle...  \n",
       "11    problem statement and description : uda reagen...  \n",
       "17    problem statement and description : uda reagen...  \n",
       "24    tss quinn documenting under supervision of tss...  \n",
       "...                                                 ...  \n",
       "4370  problem statement and description : customer c...  \n",
       "4374  problem statement and description : cust calle...  \n",
       "4378  problem statement and description : cust calle...  \n",
       "4386  problem statement and description : customer i...  \n",
       "4390  problem statement and description :   customer...  \n",
       "\n",
       "[906 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#tokenize the text by combining it into one column for each row\n",
    "#load nlp model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "#use pd to date time to utilize in the mapping of the data over time\n",
    "df_filtered_AZ['Incident Close Loc Dt'] = pd.to_datetime(df_filtered_AZ['Incident Close Loc Dt'])\n",
    "#Combine the text columns into a single text column for analysis\n",
    "df_filtered_AZ['combined_text'] = df_filtered_AZ.astype(str).agg(' '.join, axis = 1)\n",
    "\n",
    "#analyze column 'Problem Dsc'\n",
    "def tokenize(text):\n",
    "    doc = nlp(text.lower())\n",
    "    return ' '.join([token.text for token in doc]) #https://stackoverflow.com/questions/57187116/how-to-modify-spacy-tokens-doc-doc-tokens-with-pipeline-components-in-spacy\n",
    "\n",
    "#df_filtered_AZ['tokenized_text'] = df_filtered_AZ['Problem Dsc'].apply(tokenize) #call the method above to the combined text column \n",
    "df_filtered_AZ.loc[:,'tokenized_text'] = df_filtered_AZ['Problem Dsc'].apply(tokenize)\n",
    "\n",
    "display(df_filtered_AZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorize the token to find phrases\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range = (1, 5))  #Bigrams and trigrams (how long each phrase can be i.e. 2 and 3)\n",
    "X = vectorizer.fit_transform(df_filtered_AZ['tokenized_text'])\n",
    "\n",
    "#Sum up the counts of each phrase\n",
    "phrase_counts = (X > 0).sum(axis=0).A1\n",
    "\n",
    "phrases = vectorizer.get_feature_names_out()\n",
    "\n",
    "phrase_counts_df = pd.DataFrame({'Phrase': phrases, 'Count': phrase_counts}).sort_values(by = 'Count', ascending = False).reset_index()\n",
    "phrase_counts_df = phrase_counts_df.drop(['index'], axis = 1)\n",
    "#phrase_counts_df = phrase_counts_df.drop(phrase_counts_df[phrase_counts_df['Count'] <= 10].index)\n",
    "#display(phrase_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8055/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1b4b1d103b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dash.dependencies import Input, Output, State\n",
    "import random\n",
    "\n",
    "def check_keywords(text, keywords):\n",
    "    return int(any(keyword in text for keyword in keywords))\n",
    "\n",
    "\n",
    "def count_keywords(text, keywords):\n",
    "    text = text.lower()\n",
    "    return {keyword: 1 if keyword in text else 0 for keyword in keywords} #binary values\n",
    "\n",
    "\n",
    "#create dash app here\n",
    "app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "app.layout = html.Div([\n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            html.H3(\"Phrase Analysis\"),\n",
    "            dcc.Dropdown(\n",
    "                id='keyword-dropdown',\n",
    "                options = [{'label': f\"{phrase} ----- {freq}\", 'value': phrase} for phrase, freq in zip(phrase_counts_df['Phrase'], phrase_counts_df['Count'])],\n",
    "                multi = True,\n",
    "                placeholder = 'Select keywords',\n",
    "                value = [],\n",
    "                style = {'width': '100%'}\n",
    "            ),\n",
    "            dbc.Button(\n",
    "                id = 'submit-button',\n",
    "                n_clicks = 0,\n",
    "                children = 'Submit',\n",
    "                color = 'primary',\n",
    "                style = {'margin-top': '10px'}\n",
    "            ),\n",
    "        ], width = {'size': '8'},\n",
    "            style = {'font-size': '16px', 'text-align':'left'}),\n",
    "        dbc.Col([\n",
    "            html.H2(\"Toggle Stack\", style={'font-size': '20px'}),\n",
    "            dcc.Checklist(\n",
    "                id = 'toggle-checklist',\n",
    "                options = [\n",
    "                    {'label': 'Grouped', 'value': 'group'},\n",
    "                    {'label': 'Percentage', 'value': 'percentage'}\n",
    "                ], value = ['True'],\n",
    "                style = {'font-size': '16px'},\n",
    "            )\n",
    "        ],style = {'text-align': 'right'})\n",
    "    ]),\n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            dcc.Graph(id = 'keyword-graph')\n",
    "        ]),\n",
    "    ]),\n",
    "\n",
    "    dbc.Row([\n",
    "        #Input keywords for the overlap observation\n",
    "        dbc.Col([ \n",
    "            html.H5(\"Input Keyword to Observe Overlap (comma separated)\"),\n",
    "            dcc.Dropdown(\n",
    "                id = \"input_2\",\n",
    "                options = [{'label': f\"{phrase} ----- {freq}\", 'value': phrase} for phrase, freq in zip(phrase_counts_df['Phrase'], phrase_counts_df['Count'])],\n",
    "                multi = True,\n",
    "                placeholder = \"Select keywords\"\n",
    "            )\n",
    "        ], width = {\"size\":6}), \n",
    "\n",
    "    ]),\n",
    "\n",
    "\n",
    "    dbc.Row([\n",
    "        dbc.Col([ #create an output for the pairs\n",
    "            html.H6(\"Percentage for Pair 1 and 2\"),\n",
    "            html.Div(id = \"output_pair_1_2\")\n",
    "        ], width = {\"size\":6}),\n",
    "    ]),\n",
    "    \n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            html.H6(\"Recommended Phrases for Pair 1 and 2\"),\n",
    "            html.Div(id = \"recommendation_1_2\")\n",
    "        ], width = {\"size\": 6}),\n",
    "        dbc.Col([\n",
    "            html.H6(\"Example of Raw Cell Data\"),\n",
    "            #create a slider with min 0 and max 4 (5 total) and iterate for each lens to change values on callback for each value changed\n",
    "            dcc.Slider(id = 'raw-text-slider', min = 0, max = 4, step = 1, value = 0, marks = {i: str(i+1) for i in range(5)}),\n",
    "            html.Div(id = 'raw-text-display')\n",
    "        ]),\n",
    "    ]),\n",
    "\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "#create app callback and mark all inputs and output id's that needs to be updated\n",
    "@app.callback(\n",
    "    [Output(component_id = \"output_pair_1_2\", component_property = \"children\"),\n",
    "    Output(component_id = \"recommendation_1_2\", component_property = \"children\")],\n",
    "    [Input(component_id = 'submit-button', component_property = 'n_clicks'),\n",
    "     Input(component_id = \"keyword-dropdown\", component_property = \"value\"),\n",
    "    Input(component_id = \"input_2\", component_property = \"value\")]\n",
    ")\n",
    "\n",
    "def update_output(n_clicks, input_1, input_2):\n",
    "    # Check if the submit button has been clicked\n",
    "    if n_clicks is None or n_clicks == 0:\n",
    "        return \"N/A\", \"N/A\"\n",
    "\n",
    "    if not input_1 or not input_2:\n",
    "        return \"N/A\", \"N/A\"\n",
    "    else:\n",
    "        keywords_1 = input_1\n",
    "        keywords_2 = input_2\n",
    "\n",
    "        #Apply the function to create binary columns\n",
    "        df_filtered_AZ['keyword_1_present'] = df_filtered_AZ['tokenized_text'].apply(lambda text: check_keywords(text, keywords=keywords_1))\n",
    "        df_filtered_AZ['keyword_2_present'] = df_filtered_AZ['tokenized_text'].apply(lambda text: check_keywords(text, keywords=keywords_2))\n",
    "\n",
    "        #Calculate percentages\n",
    "        keyword_percentage_pair_1 = (sum(df_filtered_AZ['keyword_1_present'] & df_filtered_AZ['keyword_2_present']) / sum(df_filtered_AZ['keyword_1_present'])) * 100\n",
    "\n",
    "        #Get recommendations\n",
    "        recommendation_1_2 = [phrase for phrase in phrase_counts_df['Phrase']\n",
    "                          if any(keyword in phrase for keyword in keywords_1) and any(keyword in phrase for keyword in keywords_2)]\n",
    "\n",
    "        #recommendation_1_2 = recommendation_1_2[:10]\n",
    "        #recommendation_1_2_text = f\"\\n\".join(recommendation_1_2) if recommendation_1_2 else \"No recommendations\"\n",
    "\n",
    "        return f\"{keyword_percentage_pair_1:.2f}%\", [html.P(text=recommendation) for recommendation in recommendation_1_2]\n",
    "    \n",
    "\n",
    "#####################################################################################################\n",
    "\n",
    "@app.callback(\n",
    "    Output(component_id = 'keyword-graph', component_property = 'figure'),\n",
    "    [Input(component_id = 'submit-button', component_property = 'n_clicks'),\n",
    "    Input(component_id = 'toggle-checklist', component_property = 'value')],\n",
    "    [dash.dependencies.State('keyword-dropdown', 'value')]\n",
    ")\n",
    "\n",
    "#create function that autosuggests words/phrases?\n",
    "#def word_suggestor\n",
    "\n",
    "#create function that updates figure\n",
    "def update_graph(n_clicks, toggle, keywords):  \n",
    "    #want it so that for each click, updates using property of n_clicks and changing the keywords input\n",
    "\n",
    "    #consider the case that exist empty string\n",
    "    if not keywords:\n",
    "        #return empty dict if exist empty string\n",
    "        return {}\n",
    "\n",
    "    #apply the function here which applies strip() and lower() while splitting by ','\n",
    "    df_filtered_AZ['keyword_frequency'] = df_filtered_AZ['combined_text'].apply(lambda x: count_keywords(x, keywords))\n",
    "\n",
    "    #percentage =\n",
    "    #convert back to dataframe and fill zero if missing(N/A)\n",
    "    keyword_df = df_filtered_AZ['keyword_frequency'].apply(pd.Series)\n",
    "\n",
    "    #group by date and reset the index like before\n",
    "    keyword_bydate_df = df_filtered_AZ[['Incident Close Loc Dt']].join(keyword_df).groupby('Incident Close Loc Dt').sum().reset_index()\n",
    "    keyword_bydate_df = keyword_bydate_df.melt(id_vars = ['Incident Close Loc Dt'], var_name = 'Keyword', value_name = 'Service Calls')\n",
    "    keyword_bydate_df = keyword_bydate_df.rename(columns = {'Incident Close Loc Dt': 'Date'})\n",
    "\n",
    "    yaxis_formatting = '2%' if 'percentage' in toggle else ' '\n",
    "\n",
    "    barmode = 'group' if 'group' in toggle else 'stack'\n",
    "\n",
    "    fig = px.histogram(keyword_bydate_df, x = 'Date', y = 'Service Calls', color = 'Keyword', barmode = barmode,  title='Phrase Presence Over Time')\n",
    "    fig.update_xaxes(\n",
    "        dtick=86400000.0 * 14,  # biweekly\n",
    "        ticklabelmode=\"period\"\n",
    "    )\n",
    "    fig.update_layout(yaxis_tickformat = yaxis_formatting, yaxis_title = 'Service Calls')\n",
    "\n",
    "\n",
    "    #return the fig\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "#######################################################################################################################################################\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    [Output(component_id = 'raw-text-display', component_property = 'children'),\n",
    "     Output(component_id = 'raw-text-slider', component_property = 'max')],\n",
    "    [Input(component_id= 'submit-button', component_property = 'n_clicks'),\n",
    "     Input(component_id = 'raw-text-slider', component_property = 'value')],\n",
    "    [State(component_id = 'keyword-dropdown', component_property ='value'),\n",
    "     State(component_id = 'input_2', component_property = 'value')]\n",
    ")\n",
    "\n",
    "#method to update reommendation clel\n",
    "def recommend_cell(n_clicks, slider_value, input_1, input_2):\n",
    "    if not input_1 or not input_2:\n",
    "        return \"No keywords selected.\", 0\n",
    "    \n",
    "    #consider for when submit button is clicked or not\n",
    "    if n_clicks is None or n_clicks == 0:\n",
    "        return \"N/A\", 0\n",
    "    else:\n",
    "        keywords_1 = input_1\n",
    "        keywords_2 = input_2\n",
    "\n",
    "        #Apply the function to create binary columns\n",
    "        df_filtered_AZ['keyword_1_present'] = df_filtered_AZ['tokenized_text'].apply(lambda text: check_keywords(text, keywords_1))\n",
    "        df_filtered_AZ['keyword_2_present'] = df_filtered_AZ['tokenized_text'].apply(lambda text: check_keywords(text, keywords_2))\n",
    "\n",
    "        #Filter rows where both keywords are present\n",
    "        df_filtered_both_keywords = df_filtered_AZ[(df_filtered_AZ['keyword_1_present'] == 1) & (df_filtered_AZ['keyword_2_present'] == 1)]\n",
    "\n",
    "        #minimum number of generation is 5\n",
    "        num_samples = min(5, len(df_filtered_both_keywords))\n",
    "        random_indices = random.sample(range(len(df_filtered_both_keywords)), num_samples)\n",
    "\n",
    "        #convert to a list and find the location of the random indices\n",
    "        raw_texts = df_filtered_both_keywords['Problem Dsc'].iloc[random_indices].tolist()\n",
    "\n",
    "        #minus length of raw_Texts for each slider value e.g. if 4 then subtract necessary amount to equal it\n",
    "        if raw_texts:\n",
    "            return raw_texts[slider_value], len(raw_texts) - 1\n",
    "        else:\n",
    "            return \"No matching texts found.\", 0\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug = True, port = 8055)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
